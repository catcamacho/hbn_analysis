{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72af2ec9-70cc-4d59-ad3f-e1659cabe60e",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5a3d19b-7494-4c5e-b756-788c8f2a040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import scipy.stats as scp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import scipy.signal as scs\n",
    "import json\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import combinations\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "sns.set(context='talk', style='white', font='Arial')\n",
    "\n",
    "today = date.today().strftime('%Y%m%d')\n",
    "\n",
    "project_dir = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/'\n",
    "data_dir = project_dir + 'proc/group/parcel_timeseries/sub_ts/'\n",
    "out_dir = project_dir + 'proc/group/RSA/ISPS/'\n",
    "sample_file = project_dir + 'proc/group/datasets_info/sample_gord.32k_fs_LR.pscalar.nii'\n",
    "atlas_file = project_dir + 'proc/null_lL_WG33/Gordon333_SeitzmanSubcortical.32k_fs_LR.dlabel.nii'\n",
    "os.makedirs(out_dir,exist_ok=True)\n",
    "\n",
    "ax0 = nib.load(sample_file).header.get_axis(0)\n",
    "ax1 = nib.load(sample_file).header.get_axis(1)\n",
    "\n",
    "# load timeseries data info\n",
    "subinfo = pd.read_csv(project_dir + 'proc/group/datasets/firstleveldatalabels_withpub_thresh0.8_20220412.csv', index_col=0)\n",
    "\n",
    "# get network labels\n",
    "parcel_labels = nib.load(sample_file).header.get_axis(1).name\n",
    "network_labels = []\n",
    "for s in parcel_labels:\n",
    "    b = s.split('_')\n",
    "    if len(b)<2:\n",
    "        network_labels.append(b[0])\n",
    "    else:\n",
    "        network_labels.append(b[1])\n",
    "network_labels = np.array(network_labels)\n",
    "network_names, network_sizes = np.unique(network_labels, return_counts=True)\n",
    "\n",
    "subinfo = subinfo.drop(['set','cond'], axis=1)\n",
    "subinfo = subinfo.drop_duplicates()\n",
    "\n",
    "# assign misc variables\n",
    "TR = 0.8\n",
    "niters = int(10000/len(parcel_labels))\n",
    "alpha = np.sqrt(0.05/len(parcel_labels)) #Bonferoni FDR-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ffd2d4-5ac1-4c9e-aa80-aacaa7f1b0fb",
   "metadata": {},
   "source": [
    "# declare functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc5820-9425-4a26-a361-269e4d563f76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6d9ca0-3764-4bd7-872e-f43bdc4c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_ts_data(subdf, movie, datadir, outfile):\n",
    "    \"\"\"\n",
    "    combine data for each movie together into 1 file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subdf: DataFrame\n",
    "        A dataframe with subject IDs as the index. Includes IDs for all usable data.\n",
    "    movie: str\n",
    "        Corresponds with the str for the movie content to concatenate (e.g., \"DM\" or \"TP\").\n",
    "    datadir: folder path\n",
    "        Path to folder with the subject timeseries ciftis.\n",
    "    outfile: file path\n",
    "        Path including filename to save the output data of shape Ntimepoints x Nparcels x Nsubjects.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: numpy array\n",
    "        The compiled data of shape Ntimepoints x Nparcels x Nsubjects\n",
    "    \"\"\"\n",
    "    if not isinstance(subdf, pd.DataFrame):\n",
    "        subdf = pd.read_csv(subdf, index_col=0)\n",
    "    \n",
    "    for sub in subdf.index:\n",
    "        file = '{0}{1}_task-movie{2}_bold1_AP_Atlas_rescale_resid0.9_filt_gordonseitzman.32k_fs_LR.ptseries.nii'.format(datadir,sub, movie)\n",
    "        if sub == subdf.index[0]:\n",
    "            data = StandardScaler().fit_transform(nib.load(file).get_fdata())\n",
    "            data = np.expand_dims(data, axis=2)\n",
    "        else:\n",
    "            t = StandardScaler().fit_transform(nib.load(file).get_fdata())\n",
    "            t = np.expand_dims(t, axis=2)\n",
    "            data = np.concatenate([data,t],axis=2)\n",
    "    \n",
    "    print('Compile data from {0} brain regions measured at {1} timepoints from {2} participants.'.format(data.shape[1],data.shape[0],data.shape[2]))\n",
    "    np.save(outfile, data)\n",
    "    return(data)\n",
    "\n",
    "\n",
    "def intersubject_timeseries_correlation(data, outprefix, ax0=ax0, ax1=ax1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: numpy array\n",
    "        data in the shape of Ntimepoints x Nregions x Nsubjects\n",
    "    outprefix: str\n",
    "        name to save ISC data to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    intersub_isc: numpy array\n",
    "        intersubject spearman correlations in the shape of Nregions x Nsubjects x Nsubjects\n",
    "    group_isc: numpy array\n",
    "        group mean spearman correlations in the shape of Nregions\n",
    "    \"\"\"\n",
    "    subs = range(0,data.shape[2])\n",
    "    \n",
    "    intersub_isc = np.zeros((data.shape[1],data.shape[2],data.shape[2]))\n",
    "    group_isc = np.zeros((data.shape[1]))\n",
    "    mask = np.tri(data.shape[2], data.shape[2], -1, dtype=int)\n",
    "    \n",
    "    for r in range(0, data.shape[1]):\n",
    "        intersub_isc[r, :, :]= np.corrcoef(data[:, r, :], rowvar=False)\n",
    "            \n",
    "    for r in range(0, data.shape[1]):\n",
    "        group_isc[r] = np.mean(intersub_isc[r,:,:][mask==1])\n",
    "    \n",
    "    np.save(outprefix + 'intersub_timeseries_ISC.npy', intersub_isc)\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(group_isc, axis=0), (ax0, ax1))\n",
    "    nib.save(img, outprefix + 'mean_timseries_ISC.pscalar.nii')\n",
    "    \n",
    "    return(intersub_isc, group_isc)\n",
    "\n",
    "\n",
    "def intersubject_distance(data, outfile_prefix):\n",
    "    \"\"\"\n",
    "    Compute static pairwise intersubject similarity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: numpy array\n",
    "        1D array of subject data (i.e., each participant contributes exactly 1 measure)\n",
    "    outfilename: str\n",
    "        name to save distance data to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    isdistances: numpy array\n",
    "        intersubject distances in the shape of Nsubjects x Nsubjects x Nmetrics\n",
    "    \"\"\"\n",
    "    subs = range(0,data.shape[0])\n",
    "\n",
    "\n",
    "    # NN\n",
    "    nn = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        nn[c[0],c[1]] = np.max(data) - abs(data[c[0]] - data[c[1]])\n",
    "        nn[c[1],c[0]] = np.max(data) - abs(data[c[0]] - data[c[1]])\n",
    "    np.save(outfile_prefix + '_NN.npy', nn)\n",
    "\n",
    "    # AnnaK mean\n",
    "    annakmean = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        annakmean[c[0],c[1]] = (data[c[0]] + data[c[1]]) / 2\n",
    "        annakmean[c[1],c[0]] = (data[c[0]] + data[c[1]]) / 2\n",
    "    np.save(outfile_prefix + '_annakmean.npy', annakmean)\n",
    "    \n",
    "    # AnnaK max min mean\n",
    "    AnnaKmaxminmean = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        AnnaKmaxminmean[c[0],c[1]] = np.max(data) - ((data[c[0]] + data[c[1]]) / 2)\n",
    "        AnnaKmaxminmean[c[1],c[0]] = np.max(data) - ((data[c[0]] + data[c[1]]) / 2)\n",
    "    np.save(outfile_prefix + '_annakmaxminmean.npy', AnnaKmaxminmean)\n",
    "\n",
    "    # AnnaK min\n",
    "    annakmin = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        annakmin[c[0],c[1]] = min([data[c[0]],data[c[1]]])\n",
    "        annakmin[c[1],c[0]] = min([data[c[0]],data[c[1]]])\n",
    "    np.save(outfile_prefix + '_annakmin.npy', annakmin)\n",
    "\n",
    "    # AnnaK max minus min\n",
    "    annakmaxminmax = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        annakmaxminmax[c[0],c[1]] =np.max(data) -  max([data[c[0]],data[c[1]]])\n",
    "        annakmaxminmax[c[1],c[0]] = np.max(data) - max([data[c[0]],data[c[1]]])\n",
    "    np.save(outfile_prefix + '_annakmaxminmax.npy', annakmaxminmax)\n",
    "        \n",
    "    # AnnaK absmean\n",
    "    annakabsmean = np.zeros((data.shape[0],data.shape[0]))\n",
    "    combs = itertools.combinations(subs, 2)\n",
    "    for c in combs:\n",
    "        annakabsmean[c[0],c[1]] = abs(data[c[0]] - data[c[1]]) * ((data[c[0]] + data[c[1]]) / 2)\n",
    "        annakabsmean[c[1],c[0]] = abs(data[c[0]] - data[c[1]]) * ((data[c[0]] + data[c[1]]) / 2)\n",
    "    np.save(outfile_prefix + '_annakabsmean.npy', annakabsmean)\n",
    "    \n",
    "    isdistances = {'NN': nn, \n",
    "                   'AnnaKmean': annakmean, \n",
    "                   'AnnaKmin': annakmin, \n",
    "                   'AnnaKabsmean': annakabsmean, \n",
    "                   'AnnaKmaxminmean': AnnaKmaxminmean, \n",
    "                   'AnnaKmaxminmax': annakmaxminmax}\n",
    "    return(isdistances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f51f3-5eb8-4091-9f51-d7153d1e96e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f71f35-f24d-47b5-a280-3dae971b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_brain_bx_isrsa(brain_sim_data, bx_sim_data, outfilename=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    brain_sim_data: numpy ndarray\n",
    "        Data in the shape of Nsubjects x Nsubjects\n",
    "    bx_sim_data: numpy ndarray\n",
    "        Data in the shape of Nsubjects x Nsubjects\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    rsa_report: pandas DataFrame\n",
    "        Pandas DataFrame with inter-subject representational similarity statistics\n",
    "    \"\"\"\n",
    "    rsa_report = pd.DataFrame(columns=['SpearR','SpearPvalue'])\n",
    "    \n",
    "    mask = np.tri(bx_sim_data.shape[0], bx_sim_data.shape[0], -1, dtype=int)\n",
    "    bx_sim = bx_sim_data[mask==1]\n",
    "    brain_sim = brain_sim_data[mask==1]\n",
    "    \n",
    "    r, p = scp.spearmanr(bx_sim, brain_sim)\n",
    "    rsa_report.loc[0,'SpearR'] = r\n",
    "    rsa_report.loc[0,'SpearPvalue'] = p\n",
    "    if outfilename:\n",
    "        sns.scatterplot(bx_sim, brain_sim)\n",
    "        plt.title('Similarity Correlation')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outfilename)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    return(rsa_report)\n",
    "\n",
    "\n",
    "def regional_perm_bx_isrsa(regional_sim_data, bx_sim_data, outprefix, alpha=0.05, n_perms=1000, ax0=ax0, ax1=ax1):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regional_sim_data: numpy ndarray\n",
    "        Data in the shape of Nregions x Nsubjects x Nsubjects\n",
    "    bx_sim_data: numpy ndarray\n",
    "        Data in the shape of Nsubjects x Nsubjects\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    region_isrsa: numpy ndarray\n",
    "        Data in the shape of Nregions\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = np.tri(bx_sim_data.shape[1], bx_sim_data.shape[1], -1, dtype=int)\n",
    "\n",
    "    # flatten behavior lower triangle\n",
    "    bx_sim = bx_sim_data[mask==1]\n",
    "\n",
    "    region_isrsa = np.zeros((regional_sim_data.shape[0]))\n",
    "\n",
    "    for region in range(0, regional_sim_data.shape[0]):\n",
    "            brain_sim = regional_sim_data[region,:,:][mask==1]\n",
    "            r, p = scp.spearmanr(bx_sim, brain_sim)\n",
    "            region_isrsa[region] = r\n",
    "\n",
    "    shuff_bx = bx_sim\n",
    "    perm_isrsa_null = np.zeros((n_perms, regional_sim_data.shape[0]))\n",
    "\n",
    "    # make null distributions for each TR and region\n",
    "    for a in range(0,n_perms):\n",
    "        np.random.shuffle(shuff_bx)\n",
    "        for region in range(0,regional_sim_data.shape[0]):\n",
    "            brain_sim = regional_sim_data[region,:,:][mask==1]\n",
    "            r, p = scp.spearmanr(shuff_bx, brain_sim)\n",
    "            perm_isrsa_null[a, region] = r\n",
    "\n",
    "    # compute permuted P threshold per region/TR\n",
    "    raw_pvals = np.zeros(region_isrsa.shape)\n",
    "    flat_null = perm_isrsa_null.flatten()\n",
    "    for i, a in enumerate(region_isrsa):\n",
    "        raw_pvals[i] = (np.sum((flat_null>=a).astype(int)) + 1) / (flat_null.shape[0] + 1)\n",
    "        \n",
    "    # save ciftis with raw values\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(raw_pvals, axis=0), (ax0, ax1))\n",
    "    nib.save(img, outprefix + '_permsim_raw_pval.pscalar.nii')\n",
    "    \n",
    "    img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(region_isrsa, axis=0), (ax0, ax1))\n",
    "    nib.save(img, outprefix + '_permsim_raw_rho.pscalar.nii')\n",
    "    \n",
    "    \n",
    "    # save cifti with significant rhos only\n",
    "    thresh_mask = raw_pvals<alpha\n",
    "\n",
    "    # pvals\n",
    "    thresh_pval = raw_pvals\n",
    "    thresh_pval[thresh_mask==0] = np.nan\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(thresh_pval, axis=0), (ax0, ax1))\n",
    "    nib.save(img, outprefix + '_permsim_masked_pval{0}.pscalar.nii'.format(alpha))\n",
    "\n",
    "    # rhos\n",
    "    thresh_isrsa = region_isrsa\n",
    "    thresh_isrsa[thresh_mask==0] = np.nan\n",
    "    thresh_isrsa[thresh_isrsa<0] = np.nan\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(np.expand_dims(thresh_isrsa, axis=0), (ax0, ax1))\n",
    "    nib.save(img, outprefix + '_permsim_masked_rho{0}.pscalar.nii'.format(alpha))\n",
    "    return(thresh_isrsa)\n",
    "\n",
    "\n",
    "def region_isrsa_fdr(disc_rho, disc_pval, rep_rho, rep_pval, outprefix, alpha=0.05, bon_alpha=True,replace_zeros=True, ax0=ax0, ax1=ax1):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    disc_rho = nib.load(disc_rho).get_fdata()\n",
    "    disc_pval = nib.load(disc_pval).get_fdata()\n",
    "    rep_rho = nib.load(rep_rho).get_fdata()\n",
    "    rep_pval = nib.load(rep_pval).get_fdata()\n",
    "    \n",
    "    if replace_zeros:\n",
    "        disc_pval[disc_pval==0] = np.nan\n",
    "        rep_pval[rep_pval==0] = np.nan\n",
    "    \n",
    "    if bon_alpha==True:\n",
    "        bon_alpha = np.sqrt(alpha/disc_pval.shape[1])\n",
    "    else:\n",
    "        bon_alpha = alpha\n",
    "\n",
    "    dmask = (disc_pval<bon_alpha).astype(int)\n",
    "    rmask = (rep_pval<bon_alpha).astype(int)\n",
    "\n",
    "    mask = np.zeros(dmask.shape)\n",
    "    mask[(dmask==1) & (rmask==1)] = 1\n",
    "\n",
    "    bonrho = np.empty(mask.shape)\n",
    "    bonrho[mask==1] = np.add(disc_rho[mask==1],rep_rho[mask==1])/2\n",
    "    bonrho[mask==0] = np.nan\n",
    "\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(bonrho, (ax0, ax1))\n",
    "    nib.save(img, outprefix + '_maskedrho_fdr{0}.pscalar.nii'.format(round(bon_alpha,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d5fec-a88b-45db-b205-dbc39a6a446d",
   "metadata": {},
   "source": [
    "# Where in the brain are children synchronized across movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d21583-0b1f-4e86-b253-1458773a3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process isc data \n",
    "for sample in ['rubic','cbic']:\n",
    "    for movie in ['TP','DM']:\n",
    "        print(sample, movie)\n",
    "\n",
    "        sampleinfo = subinfo.loc[(subinfo['site']==sample) & (subinfo['movie']==movie),:]\n",
    "        outdir = os.path.join(out_dir, 'fullsample', 'ts_isc_{0}_movie{1}'.format(sample, movie))\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        \n",
    "        group_data_file = os.path.join(outdir, 'compiled_timeseries_data_{0}_movie{1}.npy'.format(samparcel_labelsvie))\n",
    "        if os.path.isfile(group_data_file):\n",
    "            group_data = np.load(group_data_file)\n",
    "        else:\n",
    "            group_data = compile_ts_data(sampleinfo, movie, data_dir, group_data_file)\n",
    "\n",
    "        outprefix = os.path.join(outdir, '{0}_movie{1}_'.format(sample, movie))\n",
    "        if os.path.isfile(outprefix + 'intersub_timeseries_ISC.npy'):\n",
    "            regional_sim_data = np.load(outprefix + 'intersub_timeseries_ISC.npy')\n",
    "        else:\n",
    "            regional_sim_data, mean_isc = intersubject_timeseries_correlation(group_data, outprefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7655747-bbbe-4dc6-b577-8f4fa4c5bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rubic TP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403a75fcfa2445cebe3a10e5dedfbf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rubic DM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0382222f89fa4269ab984e56e7fb3708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbic TP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad0d6c39c645ae9f8bf96206874869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbic DM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91efba170161492e9c31e1d62c36e580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute null distributions for each\n",
    "for sample in ['rubic','cbic']:\n",
    "    for movie in ['TP','DM']:\n",
    "        print(sample, movie)\n",
    "\n",
    "        sampleinfo = subinfo.loc[(subinfo['site']==sample) & (subinfo['movie']==movie),:]\n",
    "        outdir = os.path.join(out_dir, 'fullsample', 'ts_isc_{0}_movie{1}'.format(sample, movie))\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        group_data_file = os.path.join(outdir, 'compiled_timeseries_data_{0}_movie{1}.npy'.format(sample, movie))\n",
    "        \n",
    "        null_isc = np.zeros((niters, len(parcel_labels)))\n",
    "        for i in tqdm(range(0,niters)):\n",
    "            group_data = np.load(group_data_file)\n",
    "            orig_shape = group_data.shape\n",
    "            group_data = group_data.flatten()\n",
    "            np.random.shuffle(group_data)\n",
    "            group_data = group_data.reshape(orig_shape)\n",
    "            outprefix = os.path.join(outdir, 'null_{0}_movie{1}_'.format(sample, movie))\n",
    "            _ , null_isc[i,:] = intersubject_timeseries_correlation(group_data, outprefix)\n",
    "        \n",
    "        np.save(outprefix + 'full_isc.npy', null_isc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48a001de-a1ba-4ba7-a87a-16e62c5a381b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify significant parcels\n",
    "for movie in ['TP','DM']:\n",
    "    outdir = os.path.join(out_dir, 'fullsample', 'ts_isc_movie{0}'.format(movie))\n",
    "    \n",
    "    # compute discovery sample stats\n",
    "    disc_rho_file = os.path.join(out_dir,'fullsample', 'ts_isc_rubic_movie{0}'.format(movie), \n",
    "                                    'rubic_movie{0}_mean_timseries_ISC.pscalar.nii'.format(movie))\n",
    "    disc_pval_file = os.path.join(out_dir,'fullsample', 'ts_isc_rubic_movie{0}'.format(movie), \n",
    "                                    'rubic_movie{0}_intersub_timeseries_rawpval.pscalar.nii'.format(movie))\n",
    "    disc_rho = nib.load(disc_rho_file).get_fdata()\n",
    "    origshape = disc_rho.shape\n",
    "    disc_rho = disc_rho.flatten()\n",
    "    disc_null = np.load(os.path.join(out_dir,'fullsample', 'ts_isc_rubic_movie{0}'.format(movie), \n",
    "                                    'null_rubic_movie{0}_intersub_timeseries_ISC.npy'.format(movie))).flatten()\n",
    "    disc_pval = np.ones(disc_rho.shape)\n",
    "    for i in range(0,disc_rho.shape[0]):\n",
    "        disc_pval[i] = (np.sum((disc_null>=disc_rho[i]).astype(int)) + 1) / (disc_null.shape[0] + 1)\n",
    "    disc_pval = np.reshape(disc_pval, origshape)\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(disc_pval, (ax0, ax1))\n",
    "    nib.save(img, disc_pval_file)\n",
    "    disc_rho = np.reshape(disc_rho, origshape)\n",
    "    \n",
    "    # compute replication sample stats\n",
    "    rep_rho_file = os.path.join(out_dir,'fullsample', 'ts_isc_cbic_movie{0}'.format(movie), \n",
    "                                    'cbic_movie{0}_mean_timseries_ISC.pscalar.nii'.format(movie))\n",
    "    rep_pval_file = os.path.join(out_dir,'fullsample', 'ts_isc_cbic_movie{0}'.format(movie), \n",
    "                                    'cbic_movie{0}_intersub_timeseries_rawpval.pscalar.nii'.format(movie))\n",
    "    rep_rho = nib.load(rep_rho_file).get_fdata()\n",
    "    origshape = rep_rho.shape\n",
    "    rep_rho = rep_rho.flatten()\n",
    "    rep_null = np.load(os.path.join(out_dir,'fullsample', 'ts_isc_cbic_movie{0}'.format(movie), \n",
    "                                    'null_cbic_movie{0}_intersub_timeseries_ISC.npy'.format(movie))).flatten()\n",
    "    rep_pval = np.ones(rep_rho.shape)\n",
    "    for i in range(0,rep_rho.shape[0]):\n",
    "        rep_pval[i] = (np.sum((rep_null>=rep_rho[i]).astype(int)) + 1) / (rep_null.shape[0] + 1)\n",
    "    rep_pval = np.reshape(rep_pval, origshape)\n",
    "    rep_rho = np.reshape(rep_rho, origshape)\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(rep_pval, (ax0, ax1))\n",
    "    nib.save(img, rep_pval_file)\n",
    "    \n",
    "    outprefix = os.path.join(outdir, 'group_level')\n",
    "    region_isrsa_fdr(disc_rho_file, disc_pval_file, rep_rho_file, rep_pval_file, outprefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c40cf3-1f1f-42b4-b19d-eefef6af2db5",
   "metadata": {},
   "source": [
    "# Does activation similarity map onto one model of maturation better than the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5a5cc-6b18-4756-b2f9-2f77bb8528c1",
   "metadata": {},
   "source": [
    "## test each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bab7cd-dd47-4259-9b27-35dc8601b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process isc data and identify significant parcels of IS-RSA\n",
    "for mat in ['age','PPS_score']:\n",
    "    for sample in ['rubic','cbic']:\n",
    "        for movie in ['TP','DM']:\n",
    "            print(sample, movie, mat)\n",
    "\n",
    "            sampleinfo = subinfo.loc[(subinfo['site']==sample) & (subinfo['movie']==movie) & np.isfinite(subinfo[mat]),:]\n",
    "            outdir = os.path.join(out_dir, 'maturity', 'ts_isc_{0}_movie{1}_{2}'.format(sample, movie, mat))\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "            group_data_file = os.path.join(outdir, 'compiled_timeseries_data_{0}_movie{1}.npy'.format(sample, movie))\n",
    "            if os.path.isfile(group_data_file):\n",
    "                group_data = np.load(group_data_file)\n",
    "            else:\n",
    "                group_data = compile_ts_data(sampleinfo, movie, data_dir, group_data_file)\n",
    "\n",
    "            outprefix = os.path.join(outdir, '{0}_movie{1}_'.format(sample, movie))\n",
    "            if os.path.isfile(outprefix + 'intersub_timeseries_ISC.npy'):\n",
    "                regional_sim_data = np.load(outprefix + 'intersub_timeseries_ISC.npy')\n",
    "            else:\n",
    "                regional_sim_data, mean_isc = intersubject_timeseries_correlation(group_data, outprefix)\n",
    "\n",
    "            outfile_prefix = os.path.join(outdir, '{0}_movie{1}_{2}_similarity'.format(sample, movie, mat))\n",
    "            isdistances = intersubject_distance(sampleinfo['age'].to_numpy(), outfile_prefix)\n",
    "\n",
    "            for sim in ['NN', 'AnnaKmin', 'AnnaKmaxminmax']:\n",
    "                print(sample, movie, sim, mat)\n",
    "                outprefix = os.path.join(outdir, '{0}_movie{1}_{2}_{3}_similarity'.format(sample, movie, mat, sim))\n",
    "                bx_sim_data = isdistances[sim]\n",
    "                isc_rho = regional_perm_bx_isrsa(regional_sim_data, bx_sim_data, outprefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405c276-f4f6-4920-a6fb-f1682864f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat in ['age','PPS_score']:\n",
    "    for movie in ['DM','TP']:\n",
    "        analysis_outdir = os.path.join(out_dir, 'maturity', 'ts_isc_movie{0}_{1}'.format(movie, mat))\n",
    "        os.makedirs(analysis_outdir, exist_ok=True)\n",
    "\n",
    "        for sim in ['AnnaKmaxminmax','NN','AnnaKmin']:\n",
    "            disc_pval = os.path.join(out_dir, 'maturity','ts_isc_rubic_movie{0}_{1}'.format(movie, mat),\n",
    "                                     'rubic_movie{0}_{1}_{2}_similarity_permsim_raw_pval.pscalar.nii'.format(movie, mat, sim))\n",
    "            disc_rho = os.path.join(out_dir,'maturity', 'ts_isc_rubic_movie{0}_{1}'.format(movie, mat),\n",
    "                                    'rubic_movie{0}_{1}_{2}_similarity_permsim_raw_rho.pscalar.nii'.format(movie, mat, sim))\n",
    "            rep_pval = os.path.join(out_dir,'maturity', 'ts_isc_cbic_movie{0}_{1}'.format(movie, mat),\n",
    "                                    'cbic_movie{0}_{1}_{2}_similarity_permsim_raw_pval.pscalar.nii'.format(movie, mat, sim))\n",
    "            rep_rho = os.path.join(out_dir, 'maturity','ts_isc_cbic_movie{0}_{1}'.format(movie, mat),\n",
    "                                   'cbic_movie{0}_{1}_{2}_similarity_permsim_raw_rho.pscalar.nii'.format(movie, mat, sim))\n",
    "\n",
    "            outprefix = os.path.join(analysis_outdir, 'movie{0}_isc_{1}_{2}'.format(movie, mat, sim))\n",
    "            region_isrsa_fdr(disc_rho, disc_pval, rep_rho, rep_pval, outprefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43d313-01c7-499d-aebb-3811d601b74b",
   "metadata": {},
   "source": [
    "## Identify which model best fits each parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f43ef-69b8-45ce-ba1e-a37eb3e12c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = 'age'\n",
    "niters = 1000\n",
    "\n",
    "for sample in ['rubic','cbic']:\n",
    "    for movie in ['TP','DM']:\n",
    "        print(sample, movie, mat)\n",
    "        outdir = os.path.join(out_dir, 'maturity', 'ts_isc_{0}_movie{1}_{2}'.format(sample, movie, mat))\n",
    "        \n",
    "        outprefix = os.path.join(outdir, '{0}_movie{1}_'.format(sample, movie))\n",
    "        if os.path.isfile(outprefix + 'intersub_timeseries_ISC.npy'):\n",
    "            regional_sim_data = np.load(outprefix + 'intersub_timeseries_ISC.npy')\n",
    "        else:\n",
    "            regional_sim_data, mean_isc = intersubject_timeseries_correlation(group_data, outprefix)\n",
    "\n",
    "        for sim in ['NN', 'AnnaKmin', 'AnnaKmaxminmax']:\n",
    "            print(sample, movie, sim, mat)\n",
    "            sig = nib.load(os.path.join(outdir, '{0}_movie{1}_{2}_{3}_similarity_permsim_raw_pval.pscalar.nii'.format(sample, movie, mat, sim))).get_fdata()\n",
    "            rho = nib.load(os.path.join(outdir, '{0}_movie{1}_{2}_{3}_similarity_permsim_raw_rho.pscalar.nii'.format(sample, movie, mat, sim))).get_fdata()\n",
    "            sigrho = rho\n",
    "            sigrho[sig>0.05] = 0\n",
    "            sim_filename = os.path.join(outdir, '{0}_movie{1}_{2}_similarity_{3}.npy'.format(sample, movie, mat, sim))\n",
    "            simdist_filename = os.path.join(outdir, '{0}_movie{1}_{2}_similarity_{3}_bootdist.npy'.format(sample, movie, mat, sim))\n",
    "            bx_sim_data = np.load(sim_filename)\n",
    "\n",
    "            rhodist = np.zeros((niters, regional_sim_data.shape[0]))\n",
    "            for parc in range(0,regional_sim_data.shape[0]):\n",
    "                parcsim = regional_sim_data[parc,:,:]\n",
    "                if sigrho[0,parc]>0:\n",
    "                    for i in range(0,niters):\n",
    "                        bootsample_size = np.random.randint(int(regional_sim_data.shape[1]*0.5),int(regional_sim_data.shape[1]*0.75))\n",
    "                        subsampmask = np.full(regional_sim_data.shape[1], 0)\n",
    "                        subsampmask[:bootsample_size] = 1\n",
    "                        np.random.shuffle(subsampmask)\n",
    "                        subsamp_bx = bx_sim_data[subsampmask==1, :][:, subsampmask==1]\n",
    "                        subsamp_brain = parcsim[subsampmask==1, :][:, subsampmask==1]\n",
    "                        res = static_brain_bx_isrsa(subsamp_brain, subsamp_bx)\n",
    "                        rhodist[i,parc] = res.loc[0,'SpearR']\n",
    "            np.save(simdist_filename, rhodist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee4fbf-ff13-4974-af48-21c1868892fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = 'age'\n",
    "for sample in ['rubic','cbic']:\n",
    "    for movie in ['TP','DM']:\n",
    "        # per parcel, rank point estimates and identify best fitting model\n",
    "        fitkey = {'NN': {'value':1, 'cifticolor':(56/255, 147/255, 245/255, 1), 'plotcolor':'#3893f5'}, # blue\n",
    "                  'AnnaKmin': {'value':2, 'cifticolor':(235/255, 18/255, 7/255, 1), 'plotcolor': '#eb1207'}, # red\n",
    "                  'AnnaKmaxminmax': {'value':3, 'cifticolor':(255/255, 230/255, 0/255, 1), 'plotcolor': '#ffe600'}} # gold\n",
    "        sims = list(fitkey.keys())\n",
    "\n",
    "        print(sample, movie, mat)\n",
    "        outdir = os.path.join(out_dir, 'maturity', 'ts_isc_{0}_movie{1}_{2}'.format(sample, movie, mat))\n",
    "\n",
    "        # load point estimates for each model of development\n",
    "        pointests = []\n",
    "        pointestsps = []\n",
    "        distributions = []\n",
    "        for est in sims:\n",
    "            point = nib.load(os.path.join(outdir, '{0}_movie{1}_{2}_{3}_similarity_permsim_raw_rho.pscalar.nii'.format(sample, movie, mat, est))).get_fdata()\n",
    "            pointests.append(point)\n",
    "            pointps = nib.load(os.path.join(outdir, '{0}_movie{1}_{2}_{3}_similarity_permsim_raw_pval.pscalar.nii'.format(sample, movie, mat, est))).get_fdata()\n",
    "            pointestsps.append(pointps)\n",
    "            dist = np.load(os.path.join(outdir, '{0}_movie{1}_{2}_similarity_{3}_bootdist.npy'.format(sample, movie, mat, est)))\n",
    "            distributions.append(np.expand_dims(dist, axis=2))\n",
    "        distributions = np.concatenate(distributions, axis=2)\n",
    "        pointests = np.concatenate(pointests, axis=0)\n",
    "        pointestsps = np.concatenate(pointestsps, axis=0)\n",
    "\n",
    "        pointests_binarized = np.zeros_like(pointests)\n",
    "        pointests_binarized[(pointests>0) & (pointestsps<alpha)] = 1\n",
    "        sigpointestssum = np.sum(pointests_binarized, axis=0).astype(int)\n",
    "\n",
    "        rankorder = np.zeros((len(sims), pointests.shape[1]))\n",
    "        \n",
    "        for parc in range(0, sigpointestssum.shape[0]):\n",
    "            parc_bin = pointests_binarized[:,parc]\n",
    "            if sigpointestssum[parc]==1:\n",
    "                rankorder[0,parc] = np.where(parc_bin==1)[0][0] + 1\n",
    "            elif sigpointestssum[parc]==2:\n",
    "                models = np.where(parc_bin==1)[0]\n",
    "                t, p = scp.stats.ttest_rel(distributions[parc,:,models[0]],distributions[parc,:,models[1]])\n",
    "                if p<0.05:\n",
    "                    if pointests[models[0], parc] > pointests[models[1], parc]:\n",
    "                        rankorder[0,parc] = models[0] + 1\n",
    "                        rankorder[1,parc] = models[1] + 1\n",
    "                    else:\n",
    "                        rankorder[0,parc] = models[1] + 1\n",
    "                        rankorder[1,parc] = models[0] + 1\n",
    "                else:\n",
    "                    rankorder[0,parc] = int('{0}{1}'.format(models[0],models[1]))\n",
    "            elif sigpointestssum[parc]==3:\n",
    "                tpoint = pointests[:,parc]\n",
    "                rank = np.argsort(tpoint)\n",
    "                t, p = scp.stats.ttest_rel(distributions[parc,:,rank[0]],distributions[parc,:,rank[1]])\n",
    "                if p<0.05:\n",
    "                    rankorder[0,parc] = rank[0] + 1\n",
    "                    # test second versus third place\n",
    "                    t, p = scp.stats.ttest_ind(distributions[parc,:,rank[1]],distributions[parc,:,rank[2]])\n",
    "                    if p<0.05:\n",
    "                        rankorder[1,parc] = rank[1] + 1\n",
    "                        rankorder[2,parc] = rank[2] + 1\n",
    "                    else:\n",
    "                        rankorder[1,parc] = int('{0}{1}'.format(rank[1],rank[2]))\n",
    "                else:\n",
    "                    t, p = scp.stats.ttest_rel(distributions[parc,:,rank[0]],distributions[parc,:,rank[2]])\n",
    "                    if p<0.05:\n",
    "                        rankorder[0,parc] = int('{0}{1}'.format(models[0],models[1]))\n",
    "                        rankorder[1,parc] = rank[2] + 1\n",
    "                    else:\n",
    "                        rankorder[0,parc] = 123\n",
    "        np.save(os.path.join(outdir, 'model_rank_orders.npy'), rankorder)\n",
    "\n",
    "        # make a cifti with the outputs\n",
    "        ciftkey = {0: {'label':'None', 'cifticolor':(1, 1, 1, 0), 'plotcolor':'#3893f5'}, # clear\n",
    "                   1: {'label':'NN', 'cifticolor':(round(56/255,4), round(147/255,4), round(245/255,4), 1), 'plotcolor':'#3893f5'}, # blue\n",
    "                   2: {'label':'AnnaKmin', 'cifticolor':(235/255, 18/255, 7/255, 1), 'plotcolor': '#eb1207'}, # red\n",
    "                   3: {'label':'AnnaKmaxminmax', 'cifticolor':(255/255, 230/255, 0/255, 1), 'plotcolor': '#ffe600'}, # gold\n",
    "                   12: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "                   21: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "                   13: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "                   31: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "                   23: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'}, # green\n",
    "                   32: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'},\n",
    "                   123: {'label':'All', 'cifticolor':(255/255, 255/255, 255/255, 1), 'plotcolor': '#029c0c'}} # white\n",
    "\n",
    "        # make label file with best model fit\n",
    "        ax1 = nib.load(atlas_file).header.get_axis(1)\n",
    "        data = nib.load(atlas_file).get_fdata()\n",
    "        ax0 = nib.load(atlas_file).header.get_axis(0)\n",
    "        newmap=dict()\n",
    "        newmap[0] = ax0[0][1][0]\n",
    "        for a in range(0,len(parcel_labels)):\n",
    "            newmap[a+1] = (ciftkey[rankorder[0,a]]['label'] + '_n{0}'.format(a), ciftkey[rankorder[0,a]]['cifticolor'])\n",
    "        ax0.label[0] = newmap\n",
    "        img = nib.cifti2.cifti2.Cifti2Image(data, (ax0, ax1))\n",
    "        nib.save(img, os.path.join(outdir, 'top_model_fits.dlabel.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b5969-63b1-4a34-a2d3-90d81e479ee5",
   "metadata": {},
   "source": [
    "### make cifti of best models within each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87d17c-7be1-45d2-acfe-5d1e47a88a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = 'age'\n",
    "ciftkey = {0: {'label':'None', 'cifticolor':(1, 1, 1, 0), 'plotcolor':'#3893f5'}, # clear\n",
    "           1: {'label':'NN', 'cifticolor':(round(56/255,4), round(147/255,4), round(245/255,4), 1), 'plotcolor':'#3893f5'}, # blue\n",
    "           2: {'label':'AnnaKmin', 'cifticolor':(235/255, 18/255, 7/255, 1), 'plotcolor': '#eb1207'}, # red\n",
    "           3: {'label':'AnnaKmaxminmax', 'cifticolor':(255/255, 230/255, 0/255, 1), 'plotcolor': '#ffe600'}, # gold\n",
    "           12: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "           21: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "           13: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "           31: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "           23: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'}, # green\n",
    "           32: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'},\n",
    "           123: {'label':'All', 'cifticolor':(255/255, 255/255, 255/255, 1), 'plotcolor': '#029c0c'}} # white\n",
    "\n",
    "for movie in ['TP','DM']:\n",
    "    disc_fits = np.load(os.path.join(out_dir, 'maturity', 'ts_isc_rubic_movie{0}_{1}'.format(movie, mat), 'model_rank_orders.npy'))\n",
    "    rep_fits = np.load(os.path.join(out_dir, 'maturity', 'ts_isc_cbic_movie{0}_{1}'.format(movie, mat), 'model_rank_orders.npy'))\n",
    "\n",
    "    outdir = os.path.join(out_dir, 'maturity', 'ts_isc_movie{0}_{1}'.format(movie, mat))\n",
    "   \n",
    "    ### make a cifti with the outputs\n",
    "    # make label file with best model fit\n",
    "    mask = np.zeros((disc_fits.shape[1]))\n",
    "    mask[(disc_fits[0]==rep_fits[0])]=1\n",
    "\n",
    "    both_fits = disc_fits[0]\n",
    "    both_fits[mask==0] = 0\n",
    "    np.save(os.path.join(outdir,'replicable_top_models.npy'), both_fits)\n",
    "    \n",
    "    ax1 = nib.load(atlas_file).header.get_axis(1)\n",
    "    data = nib.load(atlas_file).get_fdata()\n",
    "    ax0 = nib.load(atlas_file).header.get_axis(0)\n",
    "    newmap=dict()\n",
    "    newmap[0] = ax0[0][1][0]\n",
    "    for a in range(0,len(parcel_labels)):\n",
    "        newmap[a+1] = (ciftkey[both_fits[a]]['label'] + '_n{0}'.format(a), ciftkey[both_fits[a]]['cifticolor'])\n",
    "    ax0.label[0] = newmap\n",
    "    img = nib.cifti2.cifti2.Cifti2Image(data, (ax0, ax1))\n",
    "    nib.save(img, os.path.join(outdir, 'top_model_fits_replicable.dlabel.nii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763df80-18e2-4916-a413-8d8f56ac2623",
   "metadata": {},
   "source": [
    "### make cifti of overlap between both movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9e5bb-e94b-41df-a47b-1e40d34a7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = os.path.join(out_dir, 'maturity', 'ts_isc_bothmovies_{0}'.format(mat))\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "DM = np.load(os.path.join(out_dir, 'maturity', 'ts_isc_movieDM_{0}'.format(mat),'replicable_top_models.npy'))\n",
    "TP = np.load(os.path.join(out_dir, 'maturity', 'ts_isc_movieTP_{0}'.format(mat),'replicable_top_models.npy'))\n",
    "\n",
    "mask = np.zeros((DM.shape[0]))\n",
    "mask[(DM==TP)]=1\n",
    "\n",
    "both_fits = DM\n",
    "both_fits[mask==0] = 0\n",
    "\n",
    "np.save(os.path.join(outdir,'samebothvideos_top_models.npy'), both_fits)\n",
    "\n",
    "ciftkey = {0: {'label':'None', 'cifticolor':(1, 1, 1, 0), 'plotcolor':'#3893f5'}, # clear\n",
    "           1: {'label':'NN', 'cifticolor':(round(56/255,4), round(147/255,4), round(245/255,4), 1), 'plotcolor':'#3893f5'}, # blue\n",
    "           2: {'label':'AnnaKmin', 'cifticolor':(235/255, 18/255, 7/255, 1), 'plotcolor': '#eb1207'}, # red\n",
    "           3: {'label':'AnnaKmaxminmax', 'cifticolor':(255/255, 230/255, 0/255, 1), 'plotcolor': '#ffe600'}, # gold\n",
    "           12: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "           21: {'label':'NN-AnnaKmin', 'cifticolor':(128/255, 4/255, 186/255, 1), 'plotcolor':'#8004ba'}, # purple\n",
    "           13: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "           31: {'label':'NN-AnnaKmaxminmax', 'cifticolor':(224/255, 152/255, 7/255, 1), 'plotcolor': '#e09807'}, # orange\n",
    "           23: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'}, # green\n",
    "           32: {'label':'AnnaKmin-AnnaKmaxminmax', 'cifticolor':(2/255, 156/255, 12/255, 1), 'plotcolor': '#029c0c'},\n",
    "           123: {'label':'All', 'cifticolor':(255/255, 255/255, 255/255, 1), 'plotcolor': '#029c0c'}} # white\n",
    "\n",
    "ax1 = nib.load(atlas_file).header.get_axis(1)\n",
    "data = nib.load(atlas_file).get_fdata()\n",
    "ax0 = nib.load(atlas_file).header.get_axis(0)\n",
    "newmap=dict()\n",
    "newmap[0] = ax0[0][1][0]\n",
    "for a in range(0,len(parcel_labels)):\n",
    "    newmap[a+1] = (ciftkey[both_fits[a]]['label'] + '_n{0}'.format(a), ciftkey[both_fits[a]]['cifticolor'])\n",
    "ax0.label[0] = newmap\n",
    "img = nib.cifti2.cifti2.Cifti2Image(data, (ax0, ax1))\n",
    "nib.save(img, os.path.join(outdir, 'top_model_fits_replicable_bothmovies.dlabel.nii'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
